{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- # CMPUT 200 Fall 2024  Ethics of Data Science and AI\n",
    " -->\n",
    "# Assignment 1: Applying and Analyzing Privacy Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "- **Dataset**: loan.csv\n",
    "- **FIRST name**: Abimbola\n",
    "- **LAST name**: Olarinde\n",
    "- **Student ID**: 1880229\n",
    "\n",
    "Leave blank if individual:\n",
    "- **Collaborator names**:\n",
    "- **Collaborator student IDs**:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will apply basic privacy techniques to a dataset of your choosing. By the end of this assignment, you should be able to:\n",
    "1. Understand and implement randomized response on binary data;\n",
    "2. Calculate the sensititivity of a non-binary feature;\n",
    "3. Add noise to a non-binary feature;\n",
    "4. Compute aggregate statistics.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "- **Collaboration**: You may choose to work alone or in a group of two. If you choose to work with a partner, you must keep the same partner for both assignments.\n",
    "If you work with a partner, your submission must be the work of your team, and both of you should submit on Canvas. If you work alone, you must submit your own work.\n",
    "The collaboration policy for the assignments is a variation Consultation Collaboration. Under this policy, you may verbally discuss concepts with your classmates, without exchanging written text, code, or detailed advice. You must develop your own solution and submit your own work (as a group or individually). All sources of information used, including books, websites, and students you talked to, must be cited in the submission. We will adhere to current Faculty of Science guidelines on dealing with suspected cases of plagiarism.\n",
    "\n",
    "- **Software**: We highly recommend that students use Google Colab for completing labs and assignments. This is the software used by the TAs in the course, and we can guarantee that there will be no issues with incompatible environments or imports.\n",
    "- **Filling out the Notebook**: You must use this notebook to complete your lab. You will execute the questions in the notebook. The questions might ask for a short answer in text form or for you to write and execute a piece of code. Make sure you enter your answer in either case only in the cell provided.\n",
    "\n",
    "- **Important**:  Do not use a different cell, do not delete cells, and do not create a new cell. Creating new cells for your code is not compatible with the auto-grading system we are using and thus your assignment will not get grading properly and you will lose marks for that question. As a reminder you must remove the raise NotImplementedError() statements from each question when answering.\n",
    "\n",
    "- **Rules for Datasets**: Any datasets used in the lab cannot be imported from cloud storage, e.g google drive, and must be read from a file either on your local computer or uploaded to the google collab notebook. Importing from cloud storage will result in a zero.\n",
    "\n",
    "- **Submission Formatting**: When you are done, you will submit your work from the notebook. Make sure to save your notebook before running it, and then submit on Canvas the notebook file with your work completed. Name your file with your Student ID number, followed by an underscore and A plus the assignment number (ex: 1234567_A1.ipynb). Failure to do so will result in your final score being reduced by 50%! Finally your name must be written at the top of the lab or assignment document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to set up; Please don't change this cell.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# These lines do some fancy plotting magic.\n",
    "import matplotlib\n",
    "# This is a magic function that renders the figure in the notebook, instead of displaying a dump of the figure object.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data\n",
    "\n",
    "**Question 1.1.** We will first load the data, carry out some cleaning and pre-processing, and inspect the data to understand what exploratory steps we will take. Name the DataFrame `df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (61, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>education_level</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>income</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Married</td>\n",
       "      <td>85000</td>\n",
       "      <td>720</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Single</td>\n",
       "      <td>62000</td>\n",
       "      <td>680</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>Student</td>\n",
       "      <td>High School</td>\n",
       "      <td>Single</td>\n",
       "      <td>25000</td>\n",
       "      <td>590</td>\n",
       "      <td>Denied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Married</td>\n",
       "      <td>105000</td>\n",
       "      <td>780</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Male</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Married</td>\n",
       "      <td>75000</td>\n",
       "      <td>710</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender  occupation education_level marital_status  income  \\\n",
       "0   32    Male    Engineer      Bachelor's        Married   85000   \n",
       "1   45  Female     Teacher        Master's         Single   62000   \n",
       "2   28    Male     Student     High School         Single   25000   \n",
       "3   51  Female     Manager      Bachelor's        Married  105000   \n",
       "4   36    Male  Accountant      Bachelor's        Married   75000   \n",
       "\n",
       "   credit_score loan_status  \n",
       "0           720    Approved  \n",
       "1           680    Approved  \n",
       "2           590      Denied  \n",
       "3           780    Approved  \n",
       "4           710    Approved  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df =  pd.read_csv('loan.csv')\n",
    "\n",
    "print(\"Shape: \", df.shape)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.2.** Describe your data and its purpose. Identify one variable that is binary or that could be classified into a binary feature. Identify another that is not a binary feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "\n",
    "My dataset contains loan application records with demographic and financial details about individuals. The purpose of the dataset is to analyze factors that influence loan approval decisions, using attributes such as age, gender, occupation, education level, marital status, income, credit score, and loan status. A binary feature is loan_status column has values \"Approved\" or \"Denied\" and A non binary feature is the credit_score column being that it has (Continuous numerical values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3.** If your data has missing values or empty rows, remove them in the cell below. If the feature that you chose above has to be classified into a binary feature, convert it. Finally, if your binary feature is categorical, convert it to numerial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>occupation</th>\n",
       "      <th>education_level</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>income</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>Male</td>\n",
       "      <td>Engineer</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Married</td>\n",
       "      <td>85000</td>\n",
       "      <td>720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>Female</td>\n",
       "      <td>Teacher</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Single</td>\n",
       "      <td>62000</td>\n",
       "      <td>680</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Male</td>\n",
       "      <td>Student</td>\n",
       "      <td>High School</td>\n",
       "      <td>Single</td>\n",
       "      <td>25000</td>\n",
       "      <td>590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>Manager</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Married</td>\n",
       "      <td>105000</td>\n",
       "      <td>780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Male</td>\n",
       "      <td>Accountant</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Married</td>\n",
       "      <td>75000</td>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>39</td>\n",
       "      <td>Male</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Married</td>\n",
       "      <td>100000</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>25</td>\n",
       "      <td>Female</td>\n",
       "      <td>Receptionist</td>\n",
       "      <td>High School</td>\n",
       "      <td>Single</td>\n",
       "      <td>32000</td>\n",
       "      <td>570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>43</td>\n",
       "      <td>Male</td>\n",
       "      <td>Banker</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>Married</td>\n",
       "      <td>95000</td>\n",
       "      <td>760</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>30</td>\n",
       "      <td>Female</td>\n",
       "      <td>Writer</td>\n",
       "      <td>Master's</td>\n",
       "      <td>Single</td>\n",
       "      <td>55000</td>\n",
       "      <td>650</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>38</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chef</td>\n",
       "      <td>Associate's</td>\n",
       "      <td>Married</td>\n",
       "      <td>65000</td>\n",
       "      <td>700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  gender    occupation education_level marital_status  income  \\\n",
       "0    32    Male      Engineer      Bachelor's        Married   85000   \n",
       "1    45  Female       Teacher        Master's         Single   62000   \n",
       "2    28    Male       Student     High School         Single   25000   \n",
       "3    51  Female       Manager      Bachelor's        Married  105000   \n",
       "4    36    Male    Accountant      Bachelor's        Married   75000   \n",
       "..  ...     ...           ...             ...            ...     ...   \n",
       "56   39    Male     Architect        Master's        Married  100000   \n",
       "57   25  Female  Receptionist     High School         Single   32000   \n",
       "58   43    Male        Banker      Bachelor's        Married   95000   \n",
       "59   30  Female        Writer        Master's         Single   55000   \n",
       "60   38    Male          Chef     Associate's        Married   65000   \n",
       "\n",
       "    credit_score  loan_status  \n",
       "0            720            0  \n",
       "1            680            0  \n",
       "2            590            1  \n",
       "3            780            0  \n",
       "4            710            0  \n",
       "..           ...          ...  \n",
       "56           770            0  \n",
       "57           570            1  \n",
       "58           760            0  \n",
       "59           650            0  \n",
       "60           700            0  \n",
       "\n",
       "[61 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert a categorical binary feature to numerical\n",
    "df['loan_status'] = df['loan_status'].map({'Approved': 0 , 'Denied': 1})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Randomized Response\n",
    "\n",
    "Now let's implement a Randomized Response mechanism. First we have to identify what the query on our **binary** variable will be. Then we can create our own randomized mechanism."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1.** Write a query on your binary feature.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "\n",
    "\n",
    "My binary feature is loan_status, which indicates whether a loan was Approved (0) or Denied (1). A query I can perform on this feature is: 'How many loan applications were denied?' This query will later be used in a randomized response mechanism to add privacy to the responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2.** Create your own randomized response mechanism for the query you defined above. You may NOT use the coin example from class, try to be creative! Ensure the mechanism adheres strictly to a 0.5 probability for truthfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "To implement a randomized response mechanism for the query 'Was the loan denied?', I will use a six-sided die method. The respondent rolls a die: if they roll a 1, 2, or 3, they answer truthfully. If they roll a 4, 5, or 6, they choose a response at random (50% chance of either 'Approved' or 'Denied').\n",
    "\n",
    "Instead of using the coin flip method, I will introduce a randomized response mechanism based on a dice roll while ensuring 50% truthfulness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3.** Implement a function for your mechanism in 2.2. in the code cell below. The function should accept a value `0` or `1` and return the reported answer according to the randomized response above. Name your function `rand_resp`. Ensure that the probability of truthfulness is exactly 0.5 in the mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to apply the randomized response mechanism\n",
    "def rand_resp(true_value):\n",
    "    \"\"\"\n",
    "    Implements a randomized response mechanism for loan_status.\n",
    "    \n",
    "    Args:\n",
    "    true_value (int): The actual loan status (0 = Approved, 1 = Denied)\n",
    "    \n",
    "    Returns:\n",
    "    int: The reported loan status after applying the randomized mechanism.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate a random number between 0 and 1\n",
    "    number = rng.random()  # Generates a value between 0 and 1\n",
    "    \n",
    "    #  If p < 0.5, return the true value (50% chance of truthfulness)\n",
    "    if number < 0.5:\n",
    "        return true_value\n",
    "    \n",
    "    # And return a random value (0 or 1) (50% chance of randomization)\n",
    "    return rng.choice([0, 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4.** For each value in your dataframe's binary feature column, call your function. Store the results in a new column in df named `rrc1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "df['rrc1'] = df['loan_status'].apply(rand_resp)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5.** Now get the **estimate** for the true number of people who answered `1`.  Write this result into the variable `count_est_true_yes`.  Given the number of reported `1`'s, we know how to estimate the proportion or number of true `1`'s.\n",
    "\n",
    "Calculate the true number of people who answered `1` (the true answer in the data we imported) and write it into the variable `count_true_yes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated true yes count:  13.5\n",
      "True yes count:  16\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "count_true_yes = df['loan_status'].sum()\n",
    "# Estimated count of \"true\" 1's based on the randomized response mechanism\n",
    "reported_ones = df['rrc1'].sum()\n",
    "N = len(df)\n",
    "\n",
    "p_truthful = 0.5  # 50% of people report the true value\n",
    "p_random = 0.25   # 25% probability of random 1s\n",
    "\n",
    "# Corrected estimation formula\n",
    "count_est_true_yes = (reported_ones - (p_random * N)) / p_truthful\n",
    "\n",
    "\n",
    "print(\"Estimated true yes count: \", count_est_true_yes)\n",
    "print(\"True yes count: \", count_true_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6.** Comment on your results from above. What can you say about the privacy-accuracy tradeoff of your randomized response mechanism?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "\n",
    "The randomized response mechanism balances privacy and accuracy. It protects individual responses by introducing randomness, but this reduces estimation precision. While the method provides strong privacy, it comes with a tradeoff where increasing privacy lowers accuracy and vice versa. In larger datasets, the estimation becomes more reliable as random noise averages out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7.** We learned in class that data analysts are still able to obtain aggregate statistics from the results of a randomized response survey. Using the column you made above, `rrc1`, to calculate the mean and median for the estimated true responses. Do the same for your true responses. Name your answers `mean_est_true_yes`, `mean_true_yes`, `median_est_true_yes`, and `median_true_yes` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  0.36065573770491804 0.26229508196721313\n",
      "Median:  0.36065573770491804 0.0\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Mean values\n",
    "mean_est_true_yes = df['rrc1'].mean()\n",
    "mean_true_yes = df['loan_status'].mean()\n",
    "\n",
    "# Median values\n",
    "median_est_true_yes = df['rrc1'].mean()\n",
    "median_true_yes = df['loan_status'].median()\n",
    "\n",
    "\n",
    "print(\"Mean: \", mean_est_true_yes, mean_true_yes)\n",
    "print(\"Median: \", median_est_true_yes, median_true_yes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.8.** Comment on your results from above. Are the results from your mechanism useable? What can you say about the privacy when it comes to randomized response? Comment on the distributions of your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "The randomized response mechanism introduces some inaccuracy, but the estimated mean and median are close to the true values. This shows that aggregate statistics remain useful despite individual-level randomness. The privacy tradeoff ensures that individual responses are protected while still allowing researchers to analyze trends in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Adding Noise\n",
    "\n",
    "We are going to use the non-binary feature that you chose earlier and add noise to it. To do this, we apply the same steps that we would for differential privacy: $f(D) + Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1.** Suppose the function we wish to query is **count**. What would the global sensitivity, $S(f)$, be? Explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "The global sensitivity  S(f) for the count function is 1 because adding or removing one data point changes the count by at most 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2.** In the cell below, write a function that adds Laplace noise to a value given the sensitivity and the privacy parameter, epsilon. Name your function `add_laplace_noise`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def add_laplace_noise(value, sensitivity=1, epsilon=1.0):\n",
    "    \"\"\"\n",
    "    Adds Laplace noise to a given value for differential privacy.\n",
    "\n",
    "    Args:\n",
    "    value (float): The true count value to which noise is added.\n",
    "    sensitivity (float): The global sensitivity of the function (default: 1 for count).\n",
    "    epsilon (float): The privacy parameter (higher epsilon = less noise, default: 1.0).\n",
    "\n",
    "    Returns:\n",
    "    float: The value with added Laplace noise.\n",
    "    \"\"\"\n",
    "    # Generate Laplace noise\n",
    "    noise = np.random.laplace(loc=0, scale=sensitivity/epsilon)\n",
    "    \n",
    "    # Return value with added noise\n",
    "    return value + noise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our query is on count, we'll have to obtain the count of each unique value of our feature.\n",
    "\n",
    "**Question 3.3.** Define a variable called that holds the count of each unique value of your feature. *Hint: there's a method that does this for us!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Define a variable to store the count of each unique credit_score value\n",
    "credit_score_counts = df['credit_score'].value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4.** Before we add noise, let's calculate some stats from your variable from 3.3. Calculate the mean, median, and count and name them `mean_count`, `median_count`, and `total_count` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of true counts: 2.1785714285714284\n",
      "Median of true counts: 2.0\n",
      "Total count of true records: 61\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "mean_count = credit_score_counts.mean()\n",
    "median_count = credit_score_counts.median()\n",
    "total_count = credit_score_counts.sum()\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean of true counts: {mean_count}\")\n",
    "print(f\"Median of true counts: {median_count}\")\n",
    "print(f\"Total count of true records: {total_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5.** Now we can start adding noise to the dataset. Use your Laplace function and your variable from 3.3. to calculate a noisy representation of each value in your feature. Set your value of epsilon to 1 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit_score\n",
      "720    5.275484\n",
      "740    5.846312\n",
      "760    4.654777\n",
      "780    4.212238\n",
      "790    2.344271\n",
      "750    2.715986\n",
      "770    2.306841\n",
      "700    2.484512\n",
      "800    2.366021\n",
      "710    1.794576\n",
      "570   -0.659263\n",
      "810    1.702241\n",
      "600    2.921430\n",
      "670    1.108534\n",
      "630    0.586865\n",
      "650   -0.514650\n",
      "680    1.927504\n",
      "730    0.417890\n",
      "690   -1.034217\n",
      "620    1.072538\n",
      "640    2.507929\n",
      "590   -0.504505\n",
      "580    1.035264\n",
      "610    0.031076\n",
      "820   -0.656658\n",
      "560   -0.026635\n",
      "660    1.001825\n",
      "830    0.296058\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "# Apply Laplace noise to each unique credit_score count\n",
    "noisy_credit_score_counts = credit_score_counts.apply(lambda x: add_laplace_noise(x, sensitivity=1, epsilon=1.0))\n",
    "\n",
    "# Display the noisy credit score counts\n",
    "print(noisy_credit_score_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6.** Now calculate the stats for your noisy values. Calculate the mean, median, and count and name them `mean_noisy_count`, `median_noisy_count`, and `total_noisy_count` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy mean of true counts: 1.6147944458941736\n",
      "Noisy median of true counts: 1.405387458451776\n",
      "Total noisy count of true records: 1.6147944458941736\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "mean_noisy_count = noisy_credit_score_counts.mean()\n",
    "median_noisy_count = noisy_credit_score_counts.median()\n",
    "total_noisy_count  = noisy_credit_score_counts.mean()\n",
    "\n",
    "print(f\"Noisy mean of true counts: {mean_noisy_count}\")\n",
    "print(f\"Noisy median of true counts: {median_noisy_count}\")\n",
    "print(f\"Total noisy count of true records: {total_noisy_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.7.** Comment on the differences in aggregate statistics between the original and the noisy values. What can you say about the utility and privacy?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "The overall stats comparing the original and noisy data show minor variations because of the Laplace noise. The mean, median, and total numbers shift slightly but stay near their original values, indicating that the noise keeps the big-picture trends intact. This balance shows the tension between utility and privacy: a bit of precision is sacrificed, but individual data stays secure. The method works well, delivering valuable insights while upholding differential privacy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.8.** Go back to question 3.5. and change the value of epsilon. Repeat this until you notice a pattern in your aggregate statistics. What happens as epsilon changes? What happens to the privacy and the accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE\n",
    "\n",
    "As epsilon increases, less noise is added, making the noisy statistics more accurate but reducing privacy. When epsilon decreases, more noise is added, increasing privacy but making the statistics less reliable. This highlights the tradeoff between accuracy and privacy: higher epsilon values improve data utility, while lower epsilon values provide stronger privacy protection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rubric\n",
    "\n",
    "| Question | Points|\n",
    "|----------|----------|\n",
    "| 1.1.   | 5   |\n",
    "| 1.2.    | 10   |\n",
    "| 1.3.    | 5   |\n",
    "| 2.1.   | 5   |\n",
    "| 2.2.    | 10  |\n",
    "| 2.3.  | 10   |\n",
    "| 2.4.    | 2   |\n",
    "| 2.5.   | 8   |\n",
    "| 2.6.   | 5   |\n",
    "| 2.7.   | 6   |\n",
    "| 2.8.   | 8   |\n",
    "| 3.1.   | 2   |\n",
    "| 3.2.    | 10  |\n",
    "| 3.3.  | 5   |\n",
    "| 3.4.    | 3   |\n",
    "| 3.5.   | 5   |\n",
    "| 3.6.   | 3   |\n",
    "| 3.7.   | 5   |\n",
    "| 3.8.   | 8   |\n",
    "| Total  | 115   |\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
